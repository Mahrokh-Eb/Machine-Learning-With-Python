{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-linearClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM32VKx3xDvIX5WdyMUqeC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahrokh-Eb/Machine-Learning-With-Python/blob/master/feb2022/3_linearClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## link too google drive -lecture-7\n"
      ],
      "metadata": {
        "id": "txyXv2Oci8W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/numpy/cifar-10-batches-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJb5OCbIjDQk",
        "outputId": "3b72d63a-d5eb-462f-a002-1e65583fd088"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/numpy/cifar-10-batches-py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import layers"
      ],
      "metadata": {
        "id": "3p3UZVlokGx9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "4022a9e4-52f0-4854-a190-e8abe3449973"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8ef9f9cb0280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'layers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading ccifar 10"
      ],
      "metadata": {
        "id": "iy4WLXB0jR8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "def load_cifar10_batch(filename):\n",
        "    \"\"\" Load a single batch from CIFAR10 \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='bytes')\n",
        "        X = datadict[b'data']\n",
        "        Y = datadict[b'labels']\n",
        "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype('float')\n",
        "        Y = np.array(Y)\n",
        "        return X, Y\n",
        "    \n",
        "def load_cifar10(dir):\n",
        "    \"\"\" Load all batches of CIFAR10 \"\"\"\n",
        "    # load train batch file\n",
        "    xs = []\n",
        "    ys = []\n",
        "    \n",
        "    for i in range(1, 6):\n",
        "        filename = os.path.join(dir, 'data_batch_%d' % i)\n",
        "        X, Y = load_cifar10_batch(filename)\n",
        "        xs.append(X)\n",
        "        ys.append(Y)\n",
        "        \n",
        "    Xtr = np.concatenate(xs)\n",
        "    Ytr = np.concatenate(ys)\n",
        "    del X, Y\n",
        "    \n",
        "    # load test batch\n",
        "    Xte, Yte = load_cifar10_batch(os.path.join(dir, 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, Yte\n"
      ],
      "metadata": {
        "id": "U8CvF5xijKnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = load_cifar10('/content/drive/MyDrive/numpy/cifar-10-batches-py')"
      ],
      "metadata": {
        "id": "l-kk5rwHj88H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "o-QpYLwIkAFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 2))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.imshow(X_train[i].astype('uint8'), interpolation='spline16')\n",
        "    plt.title('%d' % y_train[i])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "TOdJL8D8kM1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(X_train[idx].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pDxBNtjgkhaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spliting cifar10 data"
      ],
      "metadata": {
        "id": "jG3qDliKLB00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting data iinto train, val and test\n",
        "\n",
        "num_training = 49000\n",
        "num_validation = 1000\n",
        "num_test = 1000\n",
        "num_dev = 500\n",
        "\n",
        "# validation data\n",
        "mask = range(num_training, num_training+num_validation)\n",
        "X_val = X_train[mask]\n",
        "y_val = y_train[mask]\n",
        "\n",
        "# training data\n",
        "mask = range(num_training)\n",
        "X_train = X_train[mask]\n",
        "y_train = y_train[mask]\n",
        "\n",
        "# Development data\n",
        "mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "X_dev = X_train[mask]\n",
        "y_dev = y_train[mask]\n",
        "\n",
        "# test data\n",
        "mask = range(num_test)\n",
        "X_test = X_test[mask]\n",
        "y_test = y_test[mask]\n",
        "\n",
        "print('Train data shape:        ', X_train.shape)\n",
        "print('Train labels shape:      ', y_train.shape)\n",
        "print('Validation data shape:   ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape:         ', X_test.shape)\n",
        "print('Test labels shape:       ', y_test.shape)"
      ],
      "metadata": {
        "id": "Xj_HWnCClYwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing "
      ],
      "metadata": {
        "id": "tyXASYmOOaqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping from 4D to 2D\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "\n",
        "# As a sanity check, print out the shapes of the data\n",
        "print('Training data shape:   ', X_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Test data shape:       ', X_test.shape)\n",
        "print('dev data shape:        ', X_dev.shape)"
      ],
      "metadata": {
        "id": "IhlahPTjOPO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deducting mean from each photo\n",
        "mean_image = np.mean(X_train, axis=0)\n",
        "# second: subtract the mean image from train and test data\n",
        "X_train -= mean_image\n",
        "X_val   -= mean_image\n",
        "X_test  -= mean_image\n",
        "X_dev   -= mean_image"
      ],
      "metadata": {
        "id": "KSMMKJraPdlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Forward Step"
      ],
      "metadata": {
        "id": "I1SF9ebQeOa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def affine_forward(x, W, b):\n",
        "\n",
        "  x2d = np.reshape(x, (x.shape[0],-1))\n",
        "  out = np.dot(x2d, W) + b\n",
        "  cashe = x, W, b\n",
        "  return out, cashe"
      ],
      "metadata": {
        "id": "JefA-iCKd-FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "-D4RxUG8h1Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L_i(x, y, W):\n",
        "\n",
        "    scores = W.dot(x) # scores becomes of size 10 x 1, the scores for each class\n",
        "    correct_class_score = scores[y]\n",
        "    C = W.shape[0] # number of classes, e.g. 10\n",
        "    \n",
        "    loss_i = 0.0\n",
        "    for j in range(C): # iterate over all wrong classes\n",
        "        if j == y:\n",
        "            # skip for the true class to only loop over incorrect classes\n",
        "            continue\n",
        "        # accumulate loss for the i-th example\n",
        "        loss_i += max(0, scores[j] - correct_class_score + 1.0)\n",
        "        \n",
        "    return loss_i"
      ],
      "metadata": {
        "id": "fnU91Xeeg-Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create W, b\n",
        "### Sanity check"
      ],
      "metadata": {
        "id": "5Gh40T3wx-Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating W and b\n",
        "N = X_train.shape[0]\n",
        "D = np.prod(X_train.shape[1:]) # number of features\n",
        "C = 10                        \n",
        "\n",
        "W = 0.0001 * np.random.randn(D, C)\n",
        "b = np.zeros((C,))\n",
        "\n",
        "# Sanity check\n",
        "from layers import affine_forward, svm_loss\n",
        "scores, _ = affine_forward(X_train, W, b)\n",
        "loss, _ = svm_loss(scores, y_train, W, reg= 0.0)"
      ],
      "metadata": {
        "id": "-Y7cUI4njDZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fFUD_2N4wyk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}