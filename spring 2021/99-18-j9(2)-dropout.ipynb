{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smart-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import layers\n",
    "from layers import affine_relu_forward, affine_backward\n",
    "from data_utils import get_CIFAR10_data\n",
    "from fc_net import FullyConnectedNet\n",
    "from solver import Solver\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removed-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'all': lambda x:\"%.2f\" %x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liked-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (49000, 3, 32, 32)\n",
      "y_train: (49000,)\n",
      "X_val  : (1000, 3, 32, 32)\n",
      "y_val  : (1000,)\n",
      "X_test : (1000, 3, 32, 32)\n",
      "y_test : (1000,)\n"
     ]
    }
   ],
   "source": [
    "cifar10_dir = \"/Users/mahrokh/Desktop/cifar-10-batches-py\"\n",
    "data = get_CIFAR10_data(cifar10_dir)\n",
    "for k, v in data.items():\n",
    "    print('%-7s:' %k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enabling-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data['X_train'], data['y_train']\n",
    "x_val,   y_val   = data['X_val']  , data['y_val']\n",
    "x_test,  y_test  = data['X_test'] , data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-portugal",
   "metadata": {},
   "source": [
    "# implementing two layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "emotional-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import *\n",
    "\n",
    "def two_layer_network_loss(x, y, params):\n",
    "    w1, b1 = params['w1'], params['b1']\n",
    "    w2, b2 = params['w2'], params['b2']\n",
    "    \n",
    "    ################\n",
    "    # forward step #\n",
    "    ################\n",
    "    h, cache_h = affine_relu_forward(x, w1, b1)\n",
    "    scores, cache_o = affine_forward(h, w2, b2)\n",
    "    \n",
    "    #######################\n",
    "    # compute data a loss #\n",
    "    #######################\n",
    "    loss, dscore = softmax_loss(scores, y)\n",
    "    \n",
    "    ################\n",
    "    # backward step #\n",
    "    ################\n",
    "    dh, dw2, db2 = affine_backward(dscore, cache_o)\n",
    "    _, dw1, db1 = affine_relu_backward(dh, cache_h)\n",
    "    \n",
    "    grads = {'w1': dw1, 'b1': db1, 'w2': dw2, 'b2': db2}\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dried-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, params):\n",
    "    w1, b1 = params['w1'], params['b1']\n",
    "    w2, b2 = params['w2'], params['b2']\n",
    "    \n",
    "    ################\n",
    "    # forward step #\n",
    "    ################\n",
    "    h, _ = affine_relu_forward(x, w1, b1)\n",
    "    scores, _ = affine_forward(h, w2, b2)\n",
    "    \n",
    "    return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "divided-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return 100.0* np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-community",
   "metadata": {},
   "source": [
    "# Multi Layers NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "veterinary-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_network_loss(X, y, params):\n",
    "    num_layers = len(params) // 2\n",
    "    \n",
    "    ################\n",
    "    # forward step #\n",
    "    ################\n",
    "    loss = 0.0\n",
    "    cache, h = {}, X\n",
    "    \n",
    "    for i in range(1, num_layers + 1):\n",
    "        W, b = params['W%d' % i], params['b%d' % i]\n",
    "        \n",
    "        if i < num_layers:  # hidden layer\n",
    "            h, cache[i] = affine_relu_forward(h, W, b)\n",
    "        else:\n",
    "            scores, cache[i] = affine_forward(h, W, b)\n",
    "        \n",
    "        loss += 0.5 * reg * np.sum(W * W)  # regularization loss\n",
    "        \n",
    "    #####################\n",
    "    # Compute data loss #\n",
    "    #####################\n",
    "    data_loss, dscores = softmax_loss(scores, y)\n",
    "    loss += data_loss\n",
    "           \n",
    "    #################\n",
    "    # Backward step #\n",
    "    #################\n",
    "    grads = {}\n",
    "    for i in reversed(range(1, num_layers + 1)):\n",
    "        \n",
    "        if i == num_layers:  # output layer\n",
    "            dout, dW, db = affine_backward(dscores, cache[i])\n",
    "        else:  # hidden layer\n",
    "            dout, dW, db = affine_relu_backward(dout, cache[i])\n",
    "        \n",
    "        W = params['W%d' % i]\n",
    "        grads['W%d' % i] = dW + reg * W\n",
    "        grads['b%d' % i] = db\n",
    "                       \n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-count",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "handled-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, params):\n",
    "    h = x\n",
    "    for i in range (1, num_layers+1):\n",
    "        w, b = params['w%d'%i], params['b%d'%i]\n",
    "        \n",
    "        if i < num_layers: #hidden layers\n",
    "            h, _ = affine_relu_forward(h, w, b)\n",
    "        else:\n",
    "            scores, _ = affine_forward(h, w, b)\n",
    "        \n",
    "    return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-charm",
   "metadata": {},
   "source": [
    "# Minimize Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "unlimited-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = 3072\n",
    "num_output = 10\n",
    "hidden_dims = [200, 200, 200, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-management",
   "metadata": {},
   "source": [
    "#### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "genuine-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_relu_forward(x, w, b):\n",
    "    out, cache_a = affine_forward(x, w, b)\n",
    "    out, cache_r = relu_forward(out)\n",
    "    return out, (cache_a, cache_r)\n",
    "\n",
    "def affine_relu_backward(dout, cache):\n",
    "    cache_a, cache_r = cache\n",
    "    dout = relu_backward(dout, cache_r)\n",
    "    dx, dw, db = affine_backward(dout, cache_a)\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "catholic-smart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], -1))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], -1))\n",
    "y_val = np.reshape(y_val, (y_val.shape[0], -1))\n",
    "x_test = np.reshape(x_test, (x_val.shape[0], -1))\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "local-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params():\n",
    "    w = 0.001 * np.random.randn(3072, 10)\n",
    "    b = np.zeros((10,0))\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "modular-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0: loss = 27129811.97 |train accuracy = 10.39 |validation accuracy = 10.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahrokh/machineLearning with Python- razavi/practice-me/layers.py:273: RuntimeWarning: invalid value encountered in subtract\n",
      "  shifted_logits = scores - np.max(scores, axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100: loss = nan |train accuracy = 12.50 |validation accuracy =  8.70\n",
      " 200: loss = nan |train accuracy =  8.59 |validation accuracy =  8.70\n",
      " 300: loss = nan |train accuracy =  8.59 |validation accuracy =  8.70\n",
      " 400: loss = nan |train accuracy =  8.98 |validation accuracy =  8.70\n",
      " 500: loss = nan |train accuracy = 10.94 |validation accuracy =  8.70\n",
      " 600: loss = nan |train accuracy = 12.50 |validation accuracy =  8.70\n",
      " 700: loss = nan |train accuracy =  9.77 |validation accuracy =  8.70\n",
      " 800: loss = nan |train accuracy =  8.59 |validation accuracy =  8.70\n",
      " 900: loss = nan |train accuracy = 10.16 |validation accuracy =  8.70\n",
      "1000: loss = nan |train accuracy =  9.38 |validation accuracy =  8.70\n",
      "1100: loss = nan |train accuracy = 10.94 |validation accuracy =  8.70\n",
      "1200: loss = nan |train accuracy = 12.89 |validation accuracy =  8.70\n",
      "1300: loss = nan |train accuracy =  8.20 |validation accuracy =  8.70\n",
      "1400: loss = nan |train accuracy =  8.98 |validation accuracy =  8.70\n",
      "1500: loss = nan |train accuracy = 11.33 |validation accuracy =  8.70\n",
      "1600: loss = nan |train accuracy =  6.25 |validation accuracy =  8.70\n",
      "1700: loss = nan |train accuracy =  9.77 |validation accuracy =  8.70\n",
      "1800: loss = nan |train accuracy =  7.81 |validation accuracy =  8.70\n",
      "1900: loss = nan |train accuracy = 12.11 |validation accuracy =  8.70\n",
      "2000: loss = nan |train accuracy =  7.81 |validation accuracy =  8.70\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "params = {}\n",
    "dims = [num_input] + hidden_dims + [num_output]\n",
    "num_layers = len(dims) - 1\n",
    "\n",
    "for i in range(1, num_layers+1):\n",
    "    params['w%d'%i] = 0.3 * np.random.randn(dims[i-1], dims[i])\n",
    "    params['b%d'%i] = np.zeros(dims[i])\n",
    "    \n",
    "N = x_train.shape[0] \n",
    "\n",
    "# hyper parameters\n",
    "n_iterations = 2000\n",
    "batch_size = 256\n",
    "\n",
    "lr = 0.05\n",
    "reg = 1e-5\n",
    "\n",
    "loss_history = []\n",
    "best_params = params.copy()\n",
    "best_val = 0\n",
    "\n",
    "# gradient descent\n",
    "for i in range(n_iterations+1):\n",
    "    \n",
    "    # create a batch of training data\n",
    "    idx = np.random.choice(N, batch_size)\n",
    "    x_batch, y_batch = x_train[idx], y_train[idx]\n",
    "    \n",
    "    loss, grads = multi_layers_network_loss(x_batch, y_batch, params)\n",
    "    loss_history.append(loss)\n",
    "    \n",
    "    # report every 100 iterations\n",
    "    if i %100 == 0:\n",
    "        \n",
    "        y_train_pred = predict(x_batch, params)\n",
    "        train_acc = accuracy(y_train_pred, y_batch)\n",
    "        \n",
    "        y_val_pred = predict(x_val, params)\n",
    "        val_acc = accuracy(y_val_pred, y_val)\n",
    "        \n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_params = params.copy()\n",
    "            \n",
    "        print('%4d: loss = %.2f |train accuracy = %5.2f |validation accuracy = %5.2f'\n",
    "              %(i, loss, train_acc, val_acc))\n",
    "        \n",
    "    # update parameters\n",
    "    for p in params:\n",
    "        params[p] -= lr * grads[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "chemical-ranking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-racing",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "quick-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 10.30\n"
     ]
    }
   ],
   "source": [
    "test_pred = predict(x_test, best_params)\n",
    "test_accuracy = accuracy(test_pred, y_test)\n",
    "print('test accuracy = %.2f' %test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-throw",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "excited-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_forward(x, p):\n",
    "    mask = (np.random.rand(*x.shape) < (1-p))/(1-p)\n",
    "    out = x * mask\n",
    "    cache = (mask, p)\n",
    "    out = out.astype(x.dtype, copy= False)\n",
    "    return out, cache\n",
    "\n",
    "def dropout_backward(dout, cache):\n",
    "    mask, p = cache\n",
    "    dx = dout * mask\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "modern-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58 0.44 0.33 0.12 0.57 0.22 0.32 0.90 0.48 0.86]\n",
      "[0.00 0.74 0.55 0.20 0.96 0.00 0.00 1.50 0.80 1.44]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10)\n",
    "print(x)\n",
    "\n",
    "x_dropout, _ = dropout_forward(x, 0.4)\n",
    "print(x_dropout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
