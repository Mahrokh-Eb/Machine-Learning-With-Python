{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collective-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import layers\n",
    "from layers import affine_relu_forward, affine_backward\n",
    "from data_utils import get_CIFAR10_data\n",
    "from fc_net import FullyConnectedNet\n",
    "from solver import Solver\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'all': lambda x:\"%.2f\" %x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "earlier-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (49000, 3, 32, 32)\n",
      "y_train: (49000,)\n",
      "X_val  : (1000, 3, 32, 32)\n",
      "y_val  : (1000,)\n",
      "X_test : (1000, 3, 32, 32)\n",
      "y_test : (1000,)\n"
     ]
    }
   ],
   "source": [
    "cifar10_dir = \"/Users/mahrokh/Desktop/cifar-10-batches-py\"\n",
    "data = get_CIFAR10_data(cifar10_dir)\n",
    "for k, v in data.items():\n",
    "    print('%-7s:' %k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tough-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data['X_train'], data['y_train']\n",
    "x_val,   y_val   = data['X_val']  , data['y_val']\n",
    "x_test,  y_test  = data['X_test'] , data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-event",
   "metadata": {},
   "source": [
    "# implementing two layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facial-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import *\n",
    "\n",
    "def two_layer_network_loss(x, y, params):\n",
    "    w1, b1 = params['w1'], params['b1']\n",
    "    w2, b2 = params['w2'], params['b2']\n",
    "    \n",
    "    ################\n",
    "    # forward step #\n",
    "    ################\n",
    "    h, cache_h = affine_relu_forward(x, w1, b1)\n",
    "    scores, cache_o = affine_forward(h, w2, b2)\n",
    "    \n",
    "    #######################\n",
    "    # compute data a loss #\n",
    "    #######################\n",
    "    loss, dscore = softmax_loss(scores, y)\n",
    "    \n",
    "    ################\n",
    "    # backward step #\n",
    "    ################\n",
    "    dh, dw2, db2 = affine_backward(dscore, cache_o)\n",
    "    _, dw1, db1 = affine_relu_backward(dh, cache_h)\n",
    "    \n",
    "    grads = {'w1': dw1, 'b1': db1, 'w2': dw2, 'b2': db2}\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incredible-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, params):\n",
    "    w1, b1 = params['w1'], params['b1']\n",
    "    w2, b2 = params['w2'], params['b2']\n",
    "    \n",
    "    ################\n",
    "    # forward step #\n",
    "    ################\n",
    "    h, _ = affine_relu_forward(x, w1, b1)\n",
    "    scores, _ = affine_forward(h, w2, b2)\n",
    "    \n",
    "    return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "religious-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return 100.0* np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-volume",
   "metadata": {},
   "source": [
    "# Multi Layers NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exempt-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layers_network_loss(x, y, params):\n",
    "    num_layers = len(params) // 2\n",
    "    \n",
    "    # forward step\n",
    "    loss = 0.0\n",
    "    cache, h = {}, x\n",
    "    \n",
    "    for i in range (1, num_layers+1):\n",
    "        w, b = params['w%d'%i], params['b%d'%i]\n",
    "        \n",
    "        if i < num_layers: #hidden layers\n",
    "            h, cache[i] = affine_relu_forward(h, w, b)\n",
    "        else:\n",
    "            scores, cache[i] = affine_forward(h, w, b)\n",
    "            \n",
    "        loss += 0.5* reg* np.sum(w*w)\n",
    "            \n",
    "    # compute data loss\n",
    "    data_loss, dscores = softmax_loss(scores, y)\n",
    "    loss += data_loss\n",
    "    \n",
    "    # backward step\n",
    "    grads ={}\n",
    "    for i in reversed(range(1, num_layers+1)):\n",
    "        \n",
    "        if i == num_layers: #output layer\n",
    "            dout, dw, db = affine_backward(dscores, cache[i])\n",
    "                         \n",
    "        else:\n",
    "            dout, dw, db = affine_relu_backward(dout, cache[i])\n",
    "            \n",
    "        w = params['w%d' % i]\n",
    "        grads['w%d' %i] = dw + reg * w\n",
    "        grads['b%d' %i] = db\n",
    "        \n",
    "    return loss, grads      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-documentary",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "removable-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, params):\n",
    "    h = x\n",
    "    for i in range (1, num_layers+1):\n",
    "        w, b = params['w%d'%i], params['b%d'%i]\n",
    "        \n",
    "        if i < num_layers: #hidden layers\n",
    "            h, _ = affine_relu_forward(h, w, b)\n",
    "        else:\n",
    "            scores, _ = affine_forward(h, w, b)\n",
    "        \n",
    "    return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-yugoslavia",
   "metadata": {},
   "source": [
    "# Minimize Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = 3072\n",
    "num_output = 10\n",
    "hidden_dims = [200, 200, 200, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-norfolk",
   "metadata": {},
   "source": [
    "#### gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elect-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_relu_forward(x, w, b):\n",
    "    out, cache_a = affine_forward(x, w, b)\n",
    "    out, cache_r = relu_forward(out)\n",
    "    return out, (cache_a, cache_r)\n",
    "\n",
    "def affine_relu_backward(dout, cache):\n",
    "    cache_a, cache_r = cache\n",
    "    dout = relu_backward(dout, cache_r)\n",
    "    dx, dw, db = affine_backward(dout, cache_a)\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binary-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0: loss = 168636.97 |train accuracy = 10.55 |validation accuracy = 14.20\n",
      " 100: loss = 4626929983462448963765185977560501775299195035153113940419307110400.00 |train accuracy = 12.50 |validation accuracy =  7.90\n",
      " 200: loss = 4626467313482320655410563829977636489998049319713539023798181822464.00 |train accuracy = 10.94 |validation accuracy =  7.90\n",
      " 300: loss = 4626004689766888799043515409793027919569443934240407553818247561216.00 |train accuracy = 12.50 |validation accuracy =  7.90\n",
      " 400: loss = 4625542112311525228199072200117542091179919570969714695777011367936.00 |train accuracy =  7.81 |validation accuracy =  7.90\n",
      " 500: loss = 4625079581111607762722972191440397994289091728032704125671676313600.00 |train accuracy = 11.72 |validation accuracy =  7.90\n",
      " 600: loss = 4624617096162508984439085180294755776350135448402277072637211443200.00 |train accuracy =  9.38 |validation accuracy =  7.90\n",
      " 700: loss = 4624154657459602971748957590058363825389494476525146893483509809152.00 |train accuracy =  8.59 |validation accuracy =  7.90\n",
      " 800: loss = 4623692264998266796209489097798147010580149959795651200370312478720.00 |train accuracy = 10.94 |validation accuracy =  7.90\n",
      " 900: loss = 4623229918773877529377579380581030201095083045608127605457360519168.00 |train accuracy =  9.77 |validation accuracy =  7.90\n",
      "1000: loss = 4622767618781809997943613175207055905247371829146195529392008986624.00 |train accuracy = 10.16 |validation accuracy =  7.90\n",
      "1100: loss = 4622305365017441273464490158743148992209997457804192584333998948352.00 |train accuracy = 14.45 |validation accuracy =  7.90\n",
      "1200: loss = 4621843157476150672363624948523116692015844131187174573955457482752.00 |train accuracy = 13.28 |validation accuracy =  7.90\n",
      "1300: loss = 4621380996153315266197917221613883873837892996689479110416125657088.00 |train accuracy =  9.77 |validation accuracy =  7.90\n",
      "1400: loss = 4620918881044309881657751714815493045989222149494725614363358527488.00 |train accuracy =  8.98 |validation accuracy = 10.20\n",
      "1500: loss = 4620456812144518324899572925995516160222521893629406272494055194624.00 |train accuracy = 10.94 |validation accuracy =  7.90\n",
      "1600: loss = 4619994789449319164057957159065466326284042077961670824642880733184.00 |train accuracy = 12.50 |validation accuracy =  7.90\n",
      "1700: loss = 4619532812954090967267480717936856653920032551359669010644500217856.00 |train accuracy =  6.64 |validation accuracy = 10.20\n",
      "1800: loss = 4619070882654214547529234846788082613736646214902268761845964734464.00 |train accuracy = 11.72 |validation accuracy =  7.90\n",
      "1900: loss = 4618608998545069221266634162952951435766767268194525881919401361408.00 |train accuracy =  9.38 |validation accuracy =  7.90\n",
      "2000: loss = 4618147160622035053191931597187564470329914261578402238374399180800.00 |train accuracy =  7.81 |validation accuracy =  7.90\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "params = {}\n",
    "dims = [num_input] + hidden_dims + [num_output]\n",
    "num_layers = len(dims) - 1\n",
    "\n",
    "for i in range(1, num_layers+1):\n",
    "    params['w%d'%i] = 0.3 * np.random.randn(dims[i-1], dims[i])\n",
    "    params['b%d'%i] = np.zeros(dims[i])\n",
    "    \n",
    "#N = x_train.shape[0] \n",
    "N = 3072\n",
    "\n",
    "# hyper parameters\n",
    "n_iterations = 2000\n",
    "batch_size = 256\n",
    "\n",
    "lr = 0.05\n",
    "reg = 1e-5\n",
    "\n",
    "loss_history = []\n",
    "best_params = params.copy()\n",
    "best_val = 0\n",
    "\n",
    "# gradient descent\n",
    "for i in range(n_iterations+1):\n",
    "    # create a batch of training data\n",
    "    idx = np.random.choice(N, batch_size, replace=False)\n",
    "    x_batch, y_batch = x_train[idx], y_train[idx]\n",
    "    \n",
    "    loss, grads = multi_layers_network_loss(x_batch, y_batch, params)\n",
    "    loss_history.append(loss)\n",
    "    \n",
    "    # report every 100 iterations\n",
    "    if i %100 == 0:\n",
    "        \n",
    "        y_train_pred = predict(x_batch, params)\n",
    "        train_acc = accuracy(y_train_pred, y_batch)\n",
    "        \n",
    "        y_val_pred = predict(x_val, params)\n",
    "        val_acc = accuracy(y_val_pred, y_val)\n",
    "        \n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_params = params.copy()\n",
    "            \n",
    "        print('%4d: loss = %.2f |train accuracy = %5.2f |validation accuracy = %5.2f'\n",
    "              %(i, loss, train_acc, val_acc))\n",
    "        \n",
    "    # update parameters\n",
    "    for p in params:\n",
    "        params[p] -= lr * grads[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-stomach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-booth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-locking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
